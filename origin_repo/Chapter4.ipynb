{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Chapter04.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8R27gfyksk4d"},"source":["# 4章\n","- 以下で実行するコードには確率的な処理が含まれていることがあり、コードの出力結果と本書に記載されている出力例が異なることがあります。"]},{"cell_type":"code","metadata":{"id":"kvqSUAEtU_VJ"},"source":["# 4-1\n","!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DWT32lOgHLrU"},"source":["# 4-2\n","import torch\n","from transformers import BertJapaneseTokenizer, BertModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QcFsCeMBZVDR"},"source":["# 4-3\n","model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n","tokenizer = BertJapaneseTokenizer.from_pretrained(model_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gPy-VLclxU_u"},"source":["# 4-4\n","tokenizer.tokenize('明日は自然言語処理の勉強をしよう。')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fekTFJmD0-TQ"},"source":["# 4-5\n","tokenizer.tokenize('明日はマシンラーニングの勉強をしよう。')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g35K_yPf4YZL"},"source":["# 4-6\n","tokenizer.tokenize('機械学習を中国語にすると机器学习だ。')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWVOdX-Ci7zx"},"source":["# 4-7\n","input_ids = tokenizer.encode('明日は自然言語処理の勉強をしよう。')\n","print(input_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QNAPAMjCjmH-"},"source":["# 4-8\n","tokenizer.convert_ids_to_tokens(input_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FCOXUJCsxj_F"},"source":["# 4-9\n","text = '明日の天気は晴れだ。'\n","encoding = tokenizer(\n","    text, max_length=12, padding='max_length', truncation=True\n",")\n","print('# encoding:')\n","print(encoding)\n","\n","tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'])\n","print('# tokens:')\n","print(tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_KCd86ozaYH"},"source":["# 4-10\n","encoding = tokenizer(\n","    text, max_length=6, padding='max_length', truncation=True\n",")\n","tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'])\n","print(tokens)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lty7haD0kG-U"},"source":["# 4-11\n","text_list = ['明日の天気は晴れだ。','パソコンが急に動かなくなった。']\n","tokenizer(\n","    text_list, max_length=10, padding='max_length', truncation=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sv2IQ2uD2B1i"},"source":["# 4-12\n","tokenizer(text_list, padding='longest')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e9f1dK4IDzt_"},"source":["# 4-13\n","tokenizer(\n","    text_list,\n","    max_length=10,\n","    padding='max_length',\n","    truncation=True,\n","    return_tensors='pt'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ddHZWk6wLjh"},"source":["# 4-14\n","# モデルのロード\n","model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n","bert = BertModel.from_pretrained(model_name)\n","\n","# BERTをGPUに載せる\n","bert = bert.cuda() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jUG0FwjdERPP"},"source":["# 4-15\n","print(bert.config)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4Pcz2VCCChM"},"source":["# 4-16\n","text_list = [\n","    '明日は自然言語処理の勉強をしよう。',\n","    '明日はマシーンラーニングの勉強をしよう。'\n","]\n","\n","# 文章の符号化\n","encoding = tokenizer(\n","    text_list,\n","    max_length=32,\n","    padding='max_length',\n","    truncation=True,\n","    return_tensors='pt'\n",")\n","\n","# データをGPUに載せる\n","encoding = { k: v.cuda() for k, v in encoding.items() } \n","\n","# BERTでの処理\n","output = bert(**encoding) # それぞれの入力は2次元のtorch.Tensor\n","last_hidden_state = output.last_hidden_state # 最終層の出力"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vwmt3sF3gU1L"},"source":["# 4-17\n","output = bert(\n","    input_ids=encoding['input_ids'], \n","    attention_mask=encoding['attention_mask'],\n","    token_type_ids=encoding['token_type_ids']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6uDcHAPSFVlF"},"source":["# 4-18\n","print(last_hidden_state.size()) #テンソルのサイズ"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FPInM0KaPqh"},"source":["# 4-19\n","with torch.no_grad():\n","    output = bert(**encoding)\n","    last_hidden_state = output.last_hidden_state"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxAZqhrmTZOM"},"source":["# 4-20\n","last_hidden_state = last_hidden_state.cpu() # CPUにうつす。\n","last_hidden_state = last_hidden_state.numpy() # numpy.ndarrayに変換\n","last_hidden_state = last_hidden_state.tolist() # リストに変換"],"execution_count":null,"outputs":[]}]}